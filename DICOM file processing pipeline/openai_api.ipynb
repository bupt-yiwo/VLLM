{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many Chinese parts in the processed CSV file, and I used the local 72B model for translation. However, if it is a non private dataset, you can call GPT's API for translation.\n",
    "\n",
    "Of course, this code is also applicable for generating data that can be used to fine-tune large models. I have used local model to assist in generating data for single-turn description tasks, description + diagnosis tasks, multi-turn Q&A tasks, standalone pathology consultation tasks, and translation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct batch request JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "requests_data = []\n",
    "\n",
    "for dp in requests_data:\n",
    "\n",
    "    image_path = f\"xx\"\n",
    "\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    data = {\n",
    "                \"custom_id\": f\"request-{dp['count']}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"xx\"},\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"xx\"}\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "                    \"max_tokens\": 1500\n",
    "        }\n",
    "            }\n",
    "\n",
    "    with open('batch_requests_with_images.jsonl', 'a') as f:\n",
    "            f.write(json.dumps(data)  + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a batch, you can only have one piece of data in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "API_SECRET_KEY = \"zhizengzeng_key\"\n",
    "BASE_URL = \"https://api.zhizengzeng.com/v1\"; #智增增的base_url\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)\n",
    "\n",
    "def files():\n",
    "    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)\n",
    "    resp = client.files.create(\n",
    "        file=open(\"./batch_requests_with_images.jsonl\", \"rb\"),\n",
    "        purpose='batch'\n",
    "    )\n",
    "    print(resp)\n",
    "    return resp.id\n",
    "\n",
    "print(files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(file_id):\n",
    "    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)\n",
    "    resp = client.batches.create(input_file_id=file_id,\n",
    "                                 endpoint=\"/v1/chat/completions\",\n",
    "                                 completion_window=\"24h\")\n",
    "    print(resp)\n",
    "    return resp.id\n",
    "\n",
    "batches(\"xx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(bid):\n",
    "    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)\n",
    "    resp = client.batches.retrieve(bid)\n",
    "    print(resp)\n",
    "    return resp.output_file_id\n",
    "retrieve(\"xx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_result(fid):\n",
    "    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)\n",
    "    content = client.files.content(fid)\n",
    "    print(content.text)\n",
    "    return content.text\n",
    "\n",
    "\n",
    "re = get_result(\"file-xx\")\n",
    "\n",
    "json_objects = re.splitlines()  \n",
    "\n",
    "parsed_data = []\n",
    "for json_str in json_objects:\n",
    "    try:\n",
    "        parsed_data.append(json.loads(json_str))  \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "with open('extracted_mri_dialogue.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(parsed_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"xx/extracted_mri_dialogue.json\",'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(data[1]['response'][\"body\"][\"choices\"][0][\"message\"][\"content\"])[\"conversation\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single message testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "API_SECRET_KEY = \"xx\"\n",
    "BASE_URL = \"https://api.zhizengzeng.com/v1/\"\n",
    "\n",
    "client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are a professional cervical cancer specialist.\"},\n",
    "        {\n",
    "            \n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"xx\"\n",
    "                }\n",
    "\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=2000,\n",
    ")\n",
    "\n",
    "print(response)\n",
    "#print(response.choices[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
