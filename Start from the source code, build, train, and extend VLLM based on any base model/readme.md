I have combined the Qwen2VL visual encoder (650M) with the Llama3.2 (1B) language model to create a VLLM.
### Coming Soon

- Pre-training
- Downstream fine-tuning (including full fine-tuning and LoRA fine-tuning)
- Evaluation
- Web UI implementation
- Chain of Thought (CoT) reasoning
- Retrieval-Augmented Generation (RAG)
- Quantization

After completing all the work, I will refactor the code and add detailed comments.
