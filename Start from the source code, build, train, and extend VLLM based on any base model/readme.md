I have currently combined the Qwen2VL visual encoder (650M) with the Llama3.2 (1B) language model, resulting in a VLLM.
### Coming Soon
- [x] Pre-training -- done
- [x] SFT -- done
- [x] RLHF -- done
- [x] Evaluation(benchmark)
- [x] Web UI development
- [x] Retrieval-Augmented Generation (RAG) -- done
- [ ] Chain-of-Thought (COT)
- [ ] Quantization

After completing all the work, I will refactor the code and add detailed comments.
